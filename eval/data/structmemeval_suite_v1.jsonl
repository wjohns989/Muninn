{"case_id": "sme_001", "question": "What is the name of the AI memory project?", "expected_answer": "Muninn", "answer_type": "string", "memories": ["The project is called Muninn, named after Odin's raven of memory in Norse mythology.", "Muninn is an MCP-based persistent memory system for AI agents.", "The project homepage is at github.com/wjohns989/Muninn."], "relevant_memory_index": 0}
{"case_id": "sme_002", "question": "What port does the Muninn server listen on?", "expected_answer": "42069", "answer_type": "number", "memories": ["The Muninn FastAPI server runs on port 42069 by default.", "All MCP wrapper connections target http://localhost:42069.", "The port was chosen for its memorability and lack of common conflicts."], "relevant_memory_index": 0}
{"case_id": "sme_003", "question": "What Python web framework does Muninn use for its REST API?", "expected_answer": "FastAPI", "answer_type": "string", "memories": ["Muninn's REST API is built with FastAPI for high-performance async endpoint handling.", "We use uvicorn as the ASGI server for FastAPI.", "FastAPI's automatic OpenAPI schema generation simplifies client SDK creation."], "relevant_memory_index": 0}
{"case_id": "sme_004", "question": "How many tests passed in Phase 16?", "expected_answer": "788", "answer_type": "number", "memories": ["Phase 16 validation: 788 tests passed, 2 skipped, 0 failed.", "Phase 16 added 61 new tests on top of the 727 from Phase 15.", "All Phase 16 tests are in test_v3_13_0_sota_verdict_v1.py."], "relevant_memory_index": 0}
{"case_id": "sme_005", "question": "What is the company that built Muninn?", "expected_answer": "Antigravity Labs", "answer_type": "entity", "memories": ["Muninn is developed by Antigravity Labs, a developer tools company.", "Antigravity Labs focuses on AI infrastructure and open-source tooling.", "The company's flagship open-source contribution is the Muninn memory system."], "relevant_memory_index": 0}
{"case_id": "sme_006", "question": "What is the minimum LongMemEval nDCG@10 required to pass the SOTA+ gate?", "expected_answer": "0.60", "answer_type": "number", "memories": ["The LongMemEval hard gate requires minimum nDCG@10 of 0.60.", "Recall@10 minimum threshold is 0.65 for the LongMemEval gate.", "When --require-longmemeval is set and nDCG@10 < 0.60, overall_passed becomes False."], "relevant_memory_index": 0}
{"case_id": "sme_007", "question": "What open source license does Muninn use?", "expected_answer": "Apache-2.0", "answer_type": "string", "memories": ["Muninn is released under the Apache-2.0 license.", "Apache-2.0 allows commercial use, modification, and distribution with patent protection.", "The LICENSE file in the repository contains the full Apache-2.0 text."], "relevant_memory_index": 0}
{"case_id": "sme_008", "question": "What graph database powers Muninn memory chains?", "expected_answer": "KuzuDB", "answer_type": "entity", "memories": ["KuzuDB is the embedded graph database used for Muninn memory chains.", "KuzuDB stores PRECEDES and CAUSES relations between memories for causal reasoning.", "The graph data is stored in the kuzu_v12 directory under the Muninn data folder."], "relevant_memory_index": 0}
{"case_id": "sme_009", "question": "What is the current Muninn version after Phase 16?", "expected_answer": "3.13.0", "answer_type": "string", "memories": ["Muninn version 3.13.0 was released with Phase 16 (SOTA+ signed verdict v1).", "The version string is stored in muninn/version.py as __version__ = '3.13.0'.", "pyproject.toml also reflects version = '3.13.0' for packaging consistency."], "relevant_memory_index": 0}
{"case_id": "sme_010", "question": "What is the signing algorithm used for the SOTA+ promotion signature?", "expected_answer": "HMAC-SHA256", "answer_type": "string", "memories": ["The SOTA+ verdict uses HMAC-SHA256 for the promotion signature field.", "The signature format is hmac-sha256=<64 hex characters>.", "Signing requires a --signing-key argument; without it the field is null."], "relevant_memory_index": 0}
{"case_id": "sme_011", "question": "How many tests were added in Phase 15?", "expected_answer": "33", "answer_type": "number", "memories": ["Phase 15 added 33 new tests: auth propagation (5), graph chains smoke (7), OTel validation (8), LongMemEval adapter (13).", "Phase 15 brought the total test count from 694 to 727.", "Phase 15 tests are in test_v3_12_0_operational_hardening.py."], "relevant_memory_index": 0}
{"case_id": "sme_012", "question": "What vector database does Muninn use for semantic search?", "expected_answer": "Qdrant", "answer_type": "entity", "memories": ["Muninn uses Qdrant for all vector storage and semantic similarity search.", "Qdrant is chosen for its local-first operation, Rust performance, and filtering capabilities.", "The qdrant-client Python package version 1.7.0+ is required."], "relevant_memory_index": 0}
{"case_id": "sme_013", "question": "What embedding library does Muninn use by default for vector embeddings?", "expected_answer": "fastembed", "answer_type": "string", "memories": ["fastembed is the default embedding library, running ONNX models on CPU without API keys.", "The default model is BAAI/bge-small-en-v1.5 via fastembed.", "fastembed version 0.2.0+ is a required dependency in pyproject.toml."], "relevant_memory_index": 0}
{"case_id": "sme_014", "question": "What are the two MCP scope values for memory records?", "expected_answer": "project, global", "answer_type": "list", "memories": ["MemoryRecord supports two scope values: 'project' and 'global'.", "scope='project' keeps memories within their originating project repository.", "scope='global' makes memories visible across all projects regardless of current context."], "relevant_memory_index": 0}
{"case_id": "sme_015", "question": "What is the ColBERT retrieval method for scoring document-query relevance?", "expected_answer": "MaxSim", "answer_type": "string", "memories": ["ColBERT uses MaxSim (Maximum Similarity) scoring between query token embeddings and document token embeddings.", "MaxSim computes the maximum cosine similarity for each query token across all document tokens.", "Muninn implements native MaxSim in Qdrant using MultiVectorConfig."], "relevant_memory_index": 0}
{"case_id": "sme_016", "question": "What is the default chunk size in characters for ingestion?", "expected_answer": "The chunk_size_chars parameter controls chunking; overlap prevents context loss at boundaries", "answer_type": "string", "memories": ["Ingestion uses chunk_text() with configurable chunk_size_chars and chunk_overlap_chars parameters.", "Chunking normalizes whitespace and ensures min_chunk_chars minimum content per chunk.", "The chunk_overlap_chars must be less than chunk_size_chars to prevent infinite loops."], "relevant_memory_index": 0}
{"case_id": "sme_017", "question": "What PR number merged Phase 14 project-scoped memory?", "expected_answer": "43", "answer_type": "number", "memories": ["Phase 14 (v3.11.0) project-scoped memory was merged in PR #43.", "PR #43 was reviewed and had 2 Gemini review comments resolved before merging.", "PR #43 merge brought the test count to 694 with 43 new scope isolation tests."], "relevant_memory_index": 0}
{"case_id": "sme_018", "question": "What is the maximum parsed output size limit in bytes for the ingestion parser?", "expected_answer": "2000000", "answer_type": "number", "memories": ["MAX_PARSED_OUTPUT_CHARS is set to 2,000,000 characters (approximately 2MB) in parser.py.", "Output exceeding 2,000,000 characters is truncated with a [TRUNCATED] suffix.", "This limit prevents memory exhaustion from unexpectedly large source files."], "relevant_memory_index": 0}
{"case_id": "sme_019", "question": "What three relation types does the Muninn graph memory chains system support?", "expected_answer": "PRECEDES, CAUSES", "answer_type": "list", "memories": ["Muninn memory chains support PRECEDES and CAUSES edge types in KuzuDB.", "PRECEDES represents temporal ordering between memory events.", "CAUSES represents causal dependency â€” one memory directly causes another."], "relevant_memory_index": 0}
{"case_id": "sme_020", "question": "What is the name of the Python executable wrapper used by Claude Code to connect to Muninn?", "expected_answer": "mcp_wrapper.py", "answer_type": "string", "memories": ["The MCP stdio bridge is mcp_wrapper.py, a Python script in the repo root.", "Claude Code is configured to run mcp_wrapper.py as the MCP server process.", "mcp_wrapper.py handles the JSON-RPC stdio protocol and proxies to the Muninn HTTP API."], "relevant_memory_index": 0}
{"case_id": "sme_021", "question": "What OTel attribute identifies the operation type in Muninn spans?", "expected_answer": "gen_ai.operation.name", "answer_type": "string", "memories": ["Muninn OTel spans use gen_ai.operation.name as the primary operation identifier.", "gen_ai.system is also emitted to identify the memory system provider.", "Both attributes follow OpenTelemetry GenAI semantic conventions."], "relevant_memory_index": 0}
{"case_id": "sme_022", "question": "What Python minimum version does Muninn require?", "expected_answer": "3.10", "answer_type": "string", "memories": ["Muninn requires Python >= 3.10 as specified in pyproject.toml.", "Python 3.10, 3.11, 3.12, and 3.13 are all explicitly supported.", "The minimum of 3.10 enables use of match statements and modern type hints."], "relevant_memory_index": 0}
{"case_id": "sme_023", "question": "What is the schema version of the SOTA+ verdict provenance block?", "expected_answer": "1.0", "answer_type": "string", "memories": ["The verdict provenance block includes verdict_schema_version set to '1.0'.", "verdict_schema_version allows downstream consumers to parse the provenance block correctly.", "Future verdict format changes will increment the schema version for backward compatibility."], "relevant_memory_index": 0}
{"case_id": "sme_024", "question": "What are the four StructMemEval answer types?", "expected_answer": "string, number, entity, list", "answer_type": "list", "memories": ["StructMemEval defines four answer types: string, number, entity, and list.", "string: plain text facts. number: numeric values. entity: named entities. list: enumerable collections.", "Each answer type applies different matching tolerance in the evaluation metrics."], "relevant_memory_index": 0}
{"case_id": "sme_025", "question": "What is the Muninn data directory base path on Windows?", "expected_answer": "C:\\Users\\user\\AppData\\Local\\AntigravityLabs\\muninn", "answer_type": "string", "memories": ["On Windows, Muninn stores its data in C:\\Users\\user\\AppData\\Local\\AntigravityLabs\\muninn.", "The directory contains metadata.db (SQLite), qdrant_v8/ (vectors), and kuzu_v12/ (graph).", "The platformdirs library is used to determine the OS-appropriate data directory."], "relevant_memory_index": 0}
{"case_id": "sme_026", "question": "What retrieval fusion method does HybridRetriever use to combine BM25 and vector results?", "expected_answer": "reciprocal rank fusion", "answer_type": "string", "memories": ["HybridRetriever uses reciprocal rank fusion (RRF) to combine BM25 sparse and dense vector results.", "RRF assigns scores based on rank position rather than raw scores, making fusion robust to score scale differences.", "The ColBERT MaxSim scores are also integrated into the RRF pipeline."], "relevant_memory_index": 0}
{"case_id": "sme_027", "question": "What are the two external benchmark adapters in the eval directory?", "expected_answer": "longmemeval_adapter.py, structmemeval_adapter.py", "answer_type": "list", "memories": ["The eval directory contains two benchmark adapters: longmemeval_adapter.py and structmemeval_adapter.py.", "longmemeval_adapter.py implements nDCG@10 and Recall@10 for conversational QA benchmarking.", "structmemeval_adapter.py implements Exact Match, Token F1, and MRR@k for structured factoid recall."], "relevant_memory_index": 0}
{"case_id": "sme_028", "question": "What SQLite column was added in Phase 14 to enforce memory scope isolation?", "expected_answer": "scope", "answer_type": "string", "memories": ["Phase 14 added a 'scope' column (TEXT NOT NULL DEFAULT 'project') to the SQLite memories table.", "The scope column is added idempotently via _ensure_column_exists() to preserve backward compatibility.", "The scope index is created after column existence is confirmed to prevent ordering bugs."], "relevant_memory_index": 0}
{"case_id": "sme_029", "question": "What PR number introduced the SOTA+ signed verdict v1?", "expected_answer": "45", "answer_type": "number", "memories": ["PR #45 introduced Phase 16 (SOTA+ signed verdict v1) to the Muninn repository.", "PR #45 added 61 tests, the StructMemEval adapter, HMAC-SHA256 signing, and LongMemEval hard gate.", "PR #45 was merged into main on 2026-02-19 as part of the v3.13.0 release."], "relevant_memory_index": 0}
{"case_id": "sme_030", "question": "What operating systems does Muninn support?", "expected_answer": "OS Independent (Windows, Linux, macOS)", "answer_type": "string", "memories": ["Muninn is OS Independent as declared in pyproject.toml classifiers.", "It has been tested on Windows 11, Linux, and macOS.", "The platformdirs library ensures correct data directory resolution on all platforms."], "relevant_memory_index": 0}
