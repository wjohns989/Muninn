diff --git a/docs/MUNINN_COMPREHENSIVE_ROADMAP.md b/docs/MUNINN_COMPREHENSIVE_ROADMAP.md
index 798c705..67e30bf 100644
--- a/docs/MUNINN_COMPREHENSIVE_ROADMAP.md
+++ b/docs/MUNINN_COMPREHENSIVE_ROADMAP.md
@@ -159,6 +159,36 @@ Completed since last update:
    - `dev-cycle` now supports deferred mode (`--defer-benchmarks`) so active development can reuse existing live/legacy reports instead of regenerating benchmarks every tranche,
    - deferred mode now supports bounded freshness checks (`--max-reused-report-age-hours`) for reused evidence,
    - roadmap sequencing is now explicit: continue improvement/enhancement implementation with fast deterministic gates, reserve full benchmark matrix replay for release-readiness closure.
+48. Phase 4AH periodic-ingestion operational cadence baseline implemented:
+   - server lifecycle now supports optional periodic ingestion scheduling with overlap protection and runtime status tracking,
+   - authenticated control-plane endpoints now expose scheduler status + manual run + start/stop controls (`/ingest/periodic/*`),
+   - REST/MCP/SDK parity is extended for periodic-ingestion operations to keep multi-assistant workflows operationally consistent.
+49. Phase 4AI periodic-ingestion reliability hardening implemented:
+   - scheduler now applies exponential backoff + bounded jitter after failed cycles to reduce failure thrash and hot-loop risk,
+   - runtime status now exposes consecutive-failure depth and effective next-sleep diagnostics for operator visibility,
+   - deterministic tests now cover failure escalation and success-path reset semantics,
+   - periodic runs can now pin extraction to explicit model profile (`MUNINN_PERIODIC_INGESTION_MODEL_PROFILE`) for predictable latency/cost behavior,
+   - optional extraction bypass (`MUNINN_PERIODIC_INGESTION_SKIP_EXTRACTION`) now enables bulk-speed ingestion for replay/indexing workloads where entity extraction is not required.
+50. Phase 4AJ periodic-ingestion timeout governance implemented:
+   - per-memory extraction timeout control added for periodic runs (`MUNINN_PERIODIC_INGESTION_EXTRACT_TIMEOUT_SECONDS`),
+   - full periodic run timeout control added (`MUNINN_PERIODIC_INGESTION_RUN_TIMEOUT_SECONDS`) with explicit failure accounting/backoff interaction,
+   - extraction timeout path now degrades gracefully (empty extraction + continued ingest) instead of stalling the pipeline.
+51. Phase 4AK periodic-ingestion cold-start timeout hardening implemented:
+   - periodic scheduler now supports warm-up timeout bypass (`MUNINN_PERIODIC_INGESTION_RUN_TIMEOUT_SKIP_WARMUP_RUNS`) so first-run provider/model cold starts do not trigger false timeout failures,
+   - scheduler runtime status now exposes timeout-governance observability fields (`last_run_elapsed_seconds`, `last_run_timeout_enforced`),
+   - timeout-enforcement state is now returned in trigger responses for deterministic operator-side diagnostics.
+52. Phase 4AL profile-policy churn alerting baseline implemented:
+   - runtime alert evaluation added for profile-policy mutation churn with deterministic thresholds (`window`, `total churn`, `per-source churn`, `distinct-source churn`),
+   - optional webhook alert hook added for triggered churn alerts (`MUNINN_PROFILE_POLICY_ALERT_WEBHOOK_URL` + optional bearer token),
+   - REST/MCP/SDK parity shipped for alert evaluation (`GET /profiles/model/alerts`, `get_model_profile_alerts`).
+53. Phase 4AM local singleton-server lock hardening implemented:
+   - server startup now acquires a non-blocking process-level lease at `<data_dir>/.muninn_server.instance.lock` before memory/Qdrant initialization,
+   - duplicate `server.py` launches now fail fast with explicit lock-contended diagnostics instead of reaching Qdrant local lock crashes,
+   - startup contention behavior remains validated via stress harness single-owner metrics (`max_concurrent_listener_pids = 1` in current run).
+54. Phase 4AN cross-assistant MCP convergence doctor implemented:
+   - new CLI command `python -m muninn.cli doctor` validates token/url convergence across known MCP host configs plus authenticated server health,
+   - optional `--repair` now rewrites Muninn MCP entries to expected `MUNINN_AUTH_TOKEN` + `MUNINN_SERVER_URL`,
+   - `rotate-token` now patches both token and server URL to reduce drift reintroduction in multi-assistant setups.
 
 Verification:
 - Full suite now passes in-session: `418 passed, 2 skipped, 0 warnings`.
@@ -179,6 +209,11 @@ Verification:
   - `28 passed` across MCP transport protocol tests (`tests/test_mcp_wrapper_protocol.py`).
   - `30 passed` across MCP startup/bootstrap protocol tests (`tests/test_mcp_wrapper_protocol.py`) plus initialize smoke probe.
   - `11 passed` across benchmark helper apply/rollback flows (`tests/test_ollama_local_benchmark.py`).
+  - `22 passed` across periodic-ingestion slices (`tests/test_periodic_ingestion.py`, `tests/test_ingestion_manager.py`, `tests/test_memory_ingestion.py`).
+  - `128 passed` across SDK/MCP/security parity surfaces (`tests/test_sdk_client.py`, `tests/test_mcp_wrapper_protocol.py`, `tests/test_v3_6_2_security.py`).
+  - `139 passed` across profile-alerting + MCP/SDK/security slices (`tests/test_memory_profiles.py`, `tests/test_sqlite_profile_policy_events.py`, `tests/test_mcp_wrapper_protocol.py`, `tests/test_sdk_client.py`, `tests/test_v3_6_2_security.py`).
+  - `39 passed` across startup-lock hardening slices (`tests/test_server_instance_lock.py`, `tests/test_v3_12_0_operational_hardening.py`).
+  - `45 passed` across CLI convergence/rotation slices (`tests/test_cli_doctor.py`, `tests/test_cli_rotate_token.py`, `tests/test_v3_15_0_ci_token_rotation.py`).
 - Compile checks passed for all touched modules/tests.
   - unified verdict command checks now pass: compile check + `32 passed` (`tests/test_ollama_local_benchmark.py`) + `39 passed` (`tests/test_phase_hygiene.py`, `tests/test_ollama_local_benchmark.py`).
   - deferred dev-cycle checks now pass: compile check + deferred report reuse/staleness tests in `tests/test_ollama_local_benchmark.py`.
@@ -204,11 +239,12 @@ Fixed in current implementation slice:
 
 Still open and blocking SOTA claims:
 1. Benchmark corpus breadth improved (now multi-bundle), but additional domain slices are still needed for broader external validity.
-2. Parser sandbox/process-isolation for optional binary backends (`pdf/docx`) remains pending.
-3. Profile-level promotion criteria are partially open: routing, audit visibility, ability/resource benchmark plumbing, and controlled apply/rollback paths are now implemented; telemetry-backed automatic default-policy alerting and governance thresholds are still pending.
+2. Parser sandbox/process-isolation for optional binary backends (`pdf/docx`) is implemented at subprocess isolation baseline with optional POSIX resource caps; remaining gap is hard OS-level sandboxing policy on Windows (Job Objects/low-integrity equivalent) plus continuous adversarial corpus coverage.
+3. Profile-level promotion criteria are partially open: routing, audit visibility, ability/resource benchmark plumbing, controlled apply/rollback paths, and runtime profile-policy churn alerting are now implemented; remaining gap is closed-loop governance automation (CI/ops escalation policy + auto-remediation gating).
 4. Browser UI preference depth remains partially open: persistence is implemented, but advanced user-adaptive controls (profile presets, safety mode templates, benchmark launch UX) still need phased rollout.
 5. Unified SOTA+ verdict automation is partially closed: one-command promotion verdict emission + normalization hooks are now implemented; remaining work is external benchmark adapters, scheduled CI replay, and signed promotion-manifest issuance.
 6. Enhancement-vs-benchmark cadence is now codified: full matrix replay should run at release-readiness boundaries (or scheduled CI), not on every implementation tranche.
+7. Periodic ingestion cadence is now available for local/agent operations, but policy automation for benchmark replay cadence in CI remains pending.
 
 ---
 
@@ -598,6 +634,6 @@ This is core for vibecoders, not optional polish.
 4. Expand benchmark corpus with additional domain/noise/adversarial slices and refresh canonical artifact manifests.
 5. Add policy-approval manifest workflow so `dev-cycle --apply-policy` checkpoints are explicitly accepted/rejected before long-lived default policy adoption.
 6. Extend browser control center with profile-policy controls and benchmark/gate report visualization.
-7. Add alert hooks/threshold rules for profile-policy mutation events so abnormal profile churn is detectable in operations.
+7. Wire profile-policy churn alerts into production escalation paths (on-call sink, dashboard, and CI policy gates) with explicit runbook ownership.
 
 Completing these next actions keeps roadmap progression logically consistent while preserving merge hygiene, SOTA evidence quality, and operational ROI.
diff --git a/muninn/ingestion/_parser_subprocess.py b/muninn/ingestion/_parser_subprocess.py
index 01bb228..abcb820 100644
--- a/muninn/ingestion/_parser_subprocess.py
+++ b/muninn/ingestion/_parser_subprocess.py
@@ -26,12 +26,46 @@ Security properties:
 from __future__ import annotations
 
 import json
+import os
 import sys
 from pathlib import Path
 
 MAX_OUTPUT_CHARS = 2_000_000  # 2 MB cap on extracted text
 
 
+def _apply_resource_limits() -> None:
+    """Apply optional POSIX rlimits for memory/CPU when configured."""
+    if os.name != "posix":
+        return
+
+    max_memory_mb = os.environ.get("MUNINN_PARSER_MAX_MEMORY_MB")
+    max_cpu_seconds = os.environ.get("MUNINN_PARSER_MAX_CPU_SECONDS")
+
+    if not max_memory_mb and not max_cpu_seconds:
+        return
+
+    try:
+        import resource  # POSIX only
+    except Exception:
+        return
+
+    if max_memory_mb:
+        try:
+            limit_bytes = int(max_memory_mb) * 1024 * 1024
+            rlimit_as = getattr(resource, "RLIMIT_AS", None)
+            if rlimit_as is not None:
+                resource.setrlimit(rlimit_as, (limit_bytes, limit_bytes))
+        except Exception:
+            pass
+
+    if max_cpu_seconds:
+        try:
+            limit_seconds = int(max_cpu_seconds)
+            resource.setrlimit(resource.RLIMIT_CPU, (limit_seconds, limit_seconds))
+        except Exception:
+            pass
+
+
 def _parse_pdf(path: Path) -> str:
     """Extract text from a PDF file using pypdf."""
     try:
@@ -91,6 +125,7 @@ def main() -> int:
         return 1
 
     try:
+        _apply_resource_limits()
         if source_type == "pdf":
             text = _parse_pdf(file_path)
         else:  # docx
diff --git a/muninn/ingestion/sandbox.py b/muninn/ingestion/sandbox.py
index effd57f..d2d8daa 100644
--- a/muninn/ingestion/sandbox.py
+++ b/muninn/ingestion/sandbox.py
@@ -81,6 +81,9 @@ def sandboxed_parse_binary(
     source_type: str,
     *,
     timeout: float = 30.0,
+    max_bytes: Optional[int] = None,
+    max_memory_mb: Optional[int] = None,
+    max_cpu_seconds: Optional[int] = None,
     fallback_in_process: bool = False,
 ) -> str:
     """
@@ -96,6 +99,12 @@ def sandboxed_parse_binary(
         source_type: "pdf" or "docx".
         timeout: Maximum seconds to wait for the subprocess (default 30s).
                  On timeout the subprocess is killed and RuntimeError is raised.
+        max_bytes: Optional maximum file size in bytes. If set and the file size
+                   exceeds this value, parsing is rejected before subprocess launch.
+        max_memory_mb: Optional maximum memory (MB) for the parser subprocess.
+                       Enforced via POSIX rlimit if available.
+        max_cpu_seconds: Optional CPU time limit (seconds) for the parser subprocess.
+                         Enforced via POSIX rlimit if available.
         fallback_in_process: If True and subprocess fails due to infrastructure
                              reasons (not parser errors), attempt in-process parse.
                              Default False â€” safer to raise than silently bypass.
@@ -117,6 +126,22 @@ def sandboxed_parse_binary(
     if not resolved_path.exists():
         raise RuntimeError(f"File not found: {resolved_path}")
 
+    if max_bytes is not None:
+        if max_bytes <= 0:
+            raise ValueError(f"max_bytes must be positive, got: {max_bytes}")
+        file_size = resolved_path.stat().st_size
+        if file_size > max_bytes:
+            raise RuntimeError(
+                f"Binary parser rejected file larger than max_bytes "
+                f"({file_size} > {max_bytes} bytes) for {resolved_path.name}"
+            )
+
+    if (max_memory_mb is not None or max_cpu_seconds is not None) and os.name != "posix":
+        raise RuntimeError(
+            "Parser resource limits (max_memory_mb/max_cpu_seconds) "
+            "require POSIX rlimits and are unsupported on this platform."
+        )
+
     cmd = [
         sys.executable,
         "-m",
@@ -125,12 +150,22 @@ def sandboxed_parse_binary(
         str(resolved_path),
     ]
 
+    env = _make_sandbox_env()
+    if max_memory_mb is not None:
+        if max_memory_mb <= 0:
+            raise ValueError(f"max_memory_mb must be positive, got: {max_memory_mb}")
+        env["MUNINN_PARSER_MAX_MEMORY_MB"] = str(int(max_memory_mb))
+    if max_cpu_seconds is not None:
+        if max_cpu_seconds <= 0:
+            raise ValueError(f"max_cpu_seconds must be positive, got: {max_cpu_seconds}")
+        env["MUNINN_PARSER_MAX_CPU_SECONDS"] = str(int(max_cpu_seconds))
+
     try:
         result = subprocess.run(
             cmd,
             capture_output=True,
             timeout=timeout,
-            env=_make_sandbox_env(),
+            env=env,
         )
     except subprocess.TimeoutExpired as exc:
         # Kill is implicit after TimeoutExpired when using capture_output
diff --git a/tests/test_v3_21_0_parser_isolation.py b/tests/test_v3_21_0_parser_isolation.py
index 89e80e2..797c2a5 100644
--- a/tests/test_v3_21_0_parser_isolation.py
+++ b/tests/test_v3_21_0_parser_isolation.py
@@ -31,6 +31,27 @@ def test_sandboxed_parse_invalid_type():
             sandboxed_parse_binary(path, "txt")
 
 
+def test_sandboxed_parse_rejects_large_file():
+    """Files larger than max_bytes are rejected before subprocess launch."""
+    with tempfile.NamedTemporaryFile(suffix=".pdf", delete=False) as tf:
+        tf.write(b"x" * 128)
+        path = Path(tf.name)
+
+    try:
+        with pytest.raises(RuntimeError, match="rejected file larger than max_bytes"):
+            sandboxed_parse_binary(path, "pdf", max_bytes=64)
+    finally:
+        path.unlink(missing_ok=True)
+
+
+def test_sandboxed_parse_invalid_max_bytes():
+    """Non-positive max_bytes is rejected."""
+    with tempfile.NamedTemporaryFile(suffix=".pdf") as tf:
+        path = Path(tf.name)
+        with pytest.raises(ValueError, match="max_bytes must be positive"):
+            sandboxed_parse_binary(path, "pdf", max_bytes=0)
+
+
 def test_sandboxed_parse_malformed_docx():
     """Malformed DOCX should return an error from the subprocess and not crash the parent."""
     with tempfile.NamedTemporaryFile(suffix=".docx", delete=False) as tf:
